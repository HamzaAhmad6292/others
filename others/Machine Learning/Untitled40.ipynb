{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qwBk9t-KLnv1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install langchain\n",
    "!pip install langchain_chroma\n",
    "!pip install sentence_transformers\n",
    "!pip show langchain\n",
    "!pip install aiofiles\n",
    "!pip install datasets\n",
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hne2RYQqkiuX",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PrYr3ZHie9OY"
   },
   "outputs": [],
   "source": [
    "!pip install aiofiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xxPYQfQSLw4C",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"test.csv\",encoding='latin1')\n",
    "df=df.head(200)\n",
    "df.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Time of Tweet</th>\n",
       "      <th>Age of User</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population -2020</th>\n",
       "      <th>Land Area (KmÃÂ²)</th>\n",
       "      <th>Density (P/KmÃÂ²)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>neutral</td>\n",
       "      <td>morning</td>\n",
       "      <td>0-20</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>38928346.0</td>\n",
       "      <td>652860.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "      <td>positive</td>\n",
       "      <td>noon</td>\n",
       "      <td>21-30</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2877797.0</td>\n",
       "      <td>27400.0</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "      <td>negative</td>\n",
       "      <td>night</td>\n",
       "      <td>31-45</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>43851044.0</td>\n",
       "      <td>2381740.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "      <td>positive</td>\n",
       "      <td>morning</td>\n",
       "      <td>46-60</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>77265.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "      <td>positive</td>\n",
       "      <td>noon</td>\n",
       "      <td>60-70</td>\n",
       "      <td>Angola</td>\n",
       "      <td>32866272.0</td>\n",
       "      <td>1246700.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>195</td>\n",
       "      <td>03bb148b87</td>\n",
       "      <td>'I don`t like Monday, i wish it were sunday, c...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>morning</td>\n",
       "      <td>46-60</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>38928346.0</td>\n",
       "      <td>652860.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>196</td>\n",
       "      <td>b47c430fda</td>\n",
       "      <td>???    ?????? - http://bit.ly/nAcK2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>noon</td>\n",
       "      <td>60-70</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2877797.0</td>\n",
       "      <td>27400.0</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197</td>\n",
       "      <td>197</td>\n",
       "      <td>0234e16010</td>\n",
       "      <td>Waiting for the last movie to finish then am t...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>night</td>\n",
       "      <td>70-100</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>43851044.0</td>\n",
       "      <td>2381740.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>be9ed19513</td>\n",
       "      <td>Happy #StarWarsDay. May the 4th be with you!  ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>morning</td>\n",
       "      <td>0-20</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>77265.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>bf7240df91</td>\n",
       "      <td>Must head back to the office</td>\n",
       "      <td>neutral</td>\n",
       "      <td>noon</td>\n",
       "      <td>21-30</td>\n",
       "      <td>Angola</td>\n",
       "      <td>32866272.0</td>\n",
       "      <td>1246700.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0.1  Unnamed: 0      textID  \\\n",
       "0               0           0  f87dea47db   \n",
       "1               1           1  96d74cb729   \n",
       "2               2           2  eee518ae67   \n",
       "3               3           3  01082688c6   \n",
       "4               4           4  33987a8ee5   \n",
       "..            ...         ...         ...   \n",
       "195           195         195  03bb148b87   \n",
       "196           196         196  b47c430fda   \n",
       "197           197         197  0234e16010   \n",
       "198           198         198  be9ed19513   \n",
       "199           199         199  bf7240df91   \n",
       "\n",
       "                                                  text sentiment  \\\n",
       "0    Last session of the day  http://twitpic.com/67ezh   neutral   \n",
       "1     Shanghai is also really exciting (precisely -...  positive   \n",
       "2    Recession hit Veronique Branquinho, she has to...  negative   \n",
       "3                                          happy bday!  positive   \n",
       "4               http://twitpic.com/4w75p - I like it!!  positive   \n",
       "..                                                 ...       ...   \n",
       "195  'I don`t like Monday, i wish it were sunday, c...   neutral   \n",
       "196                ???    ?????? - http://bit.ly/nAcK2   neutral   \n",
       "197  Waiting for the last movie to finish then am t...   neutral   \n",
       "198  Happy #StarWarsDay. May the 4th be with you!  ...  positive   \n",
       "199                       Must head back to the office   neutral   \n",
       "\n",
       "    Time of Tweet Age of User      Country  Population -2020  \\\n",
       "0         morning        0-20  Afghanistan        38928346.0   \n",
       "1            noon       21-30      Albania         2877797.0   \n",
       "2           night       31-45      Algeria        43851044.0   \n",
       "3         morning       46-60      Andorra           77265.0   \n",
       "4            noon       60-70       Angola        32866272.0   \n",
       "..            ...         ...          ...               ...   \n",
       "195       morning       46-60  Afghanistan        38928346.0   \n",
       "196          noon       60-70      Albania         2877797.0   \n",
       "197         night      70-100      Algeria        43851044.0   \n",
       "198       morning        0-20      Andorra           77265.0   \n",
       "199          noon       21-30       Angola        32866272.0   \n",
       "\n",
       "     Land Area (KmÃÂ²)  Density (P/KmÃÂ²)  \n",
       "0              652860.0                60.0  \n",
       "1               27400.0               105.0  \n",
       "2             2381740.0                18.0  \n",
       "3                 470.0               164.0  \n",
       "4             1246700.0                26.0  \n",
       "..                  ...                 ...  \n",
       "195            652860.0                60.0  \n",
       "196             27400.0               105.0  \n",
       "197           2381740.0                18.0  \n",
       "198               470.0               164.0  \n",
       "199           1246700.0                26.0  \n",
       "\n",
       "[200 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3kyaMTu4V2tQ",
    "outputId": "4ac0e232-fd7a-437a-a97e-3861cb54b21a"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "def read_csv_to_langchain_documents(csv_file_path):\n",
    "  \"\"\"\n",
    "  Reads a CSV file and converts each row into a LangChain Document object.\n",
    "\n",
    "  Args:\n",
    "      csv_file_path (str): The path to the CSV file.\n",
    "\n",
    "  Returns:\n",
    "      list: A list of LangChain Document objects.\n",
    "  \"\"\"\n",
    "\n",
    "  documents = []\n",
    "  try:\n",
    "    with open(csv_file_path, 'r', newline='') as csvfile:\n",
    "      reader = csv.DictReader(csvfile)\n",
    "\n",
    "      for row in reader:\n",
    "        # Construct page content (adjust column names and processing as needed)\n",
    "        content = row[\"text\"]\n",
    "\n",
    "                # Create metadata using all other columns\n",
    "        metadata = {key: value for key, value in row.items() if key != \"text\"}\n",
    "\n",
    "        documents.append(Document(page_content=content, metadata=metadata))\n",
    "\n",
    "  except FileNotFoundError:\n",
    "    print(f\"Error: CSV file '{csv_file_path}' not found.\")\n",
    "  except Exception as e:\n",
    "    print(f\"An error occurred while processing the CSV file: {str(e)}\")\n",
    "\n",
    "  return documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "\n",
    "\n",
    "documents = read_csv_to_langchain_documents(\"test.csv\")\n",
    "\n",
    "\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"thenlper/gte-small\")\n",
    "\n",
    "db = Chroma.from_documents(documents, embedding_function)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query = \"yo\"\n",
    "docs = db.similarity_search(query)\n",
    "print(\"docs\")\n",
    "filter_metadata = {\"sentiment\": \"negative\"}\n",
    "filtered_documents = db.filter(where=filter_metadata)\n",
    "\n",
    "print(\"Page Content:\")\n",
    "print(filtered_documents[0].page_content)\n",
    "print(\"Meta Data:\")\n",
    "print(filtered_documents[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$and': [{'sentiment': {'$gt': 'positive'}},\n",
       "  {'country': {'$eq': 'Afghanistan'}}]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain.chains.query_constructor.ir import (\n",
    "    Comparator,\n",
    "    Comparison,\n",
    "    Operation,\n",
    "    Operator,\n",
    "    StructuredQuery,\n",
    ")\n",
    "from langchain.retrievers.self_query.chroma import ChromaTranslator\n",
    "from langchain.retrievers.self_query.elasticsearch import ElasticsearchTranslator\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Search(BaseModel):\n",
    "    query: str\n",
    "    sentiment:str\n",
    "    country: str\n",
    "\n",
    "search_query = Search(query=\"RAG\", sentiment=\"positive\", country=\"Afghanistan\")\n",
    "\n",
    "\n",
    "def construct_comparisons(query: Search):\n",
    "    comparisons = []\n",
    "    if query.sentiment is not None:\n",
    "        comparisons.append(\n",
    "            Comparison(\n",
    "                comparator=Comparator.GT,\n",
    "                attribute=\"sentiment\",\n",
    "                value=query.sentiment,\n",
    "            )\n",
    "        )\n",
    "    if query.country is not None:\n",
    "        comparisons.append(\n",
    "            Comparison(\n",
    "                comparator=Comparator.EQ,\n",
    "                attribute=\"country\",\n",
    "                value=query.country,\n",
    "            )\n",
    "        )\n",
    "    return comparisons\n",
    "\n",
    "\n",
    "comparisons = construct_comparisons(search_query)\n",
    "_filter = Operation(operator=Operator.AND, arguments=comparisons)\n",
    "\n",
    "ChromaTranslator().visit_operation(_filter)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model =  SentenceTransformer(\"dangvantuan/sentence-camembert-base\")\n",
    "\n",
    "sentences = [\"Un avion est en train de décoller.\",\n",
    "          \"Un homme joue d'une grande flûte.\",\n",
    "          \"Un homme étale du fromage râpé sur une pizza.\",\n",
    "          \"Une personne jette un chat au plafond.\",\n",
    "          \"Une personne est en train de plier un morceau de papier.\",\n",
    "          ]\n",
    "\n",
    "embeddings = model.encode(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/microsoftLLM\"\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "saved_model_dir = \"./LLM\"\n",
    "model = AutoModelForCausalLM.from_pretrained(saved_model_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(saved_model_dir)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
