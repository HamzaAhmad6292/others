{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qwBk9t-KLnv1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install langchain\n",
    "!pip install langchain_chroma\n",
    "!pip install sentence_transformers\n",
    "!pip show langchain\n",
    "!pip install aiofiles\n",
    "!pip install datasets\n",
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hne2RYQqkiuX",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PrYr3ZHie9OY"
   },
   "outputs": [],
   "source": [
    "!pip install aiofiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xxPYQfQSLw4C",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"test.csv\",encoding='latin1')\n",
    "df=df.head(200)\n",
    "df.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3kyaMTu4V2tQ",
    "outputId": "4ac0e232-fd7a-437a-a97e-3861cb54b21a"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "def read_csv_to_langchain_documents(csv_file_path):\n",
    "  \"\"\"\n",
    "  Reads a CSV file and converts each row into a LangChain Document object.\n",
    "\n",
    "  Args:\n",
    "      csv_file_path (str): The path to the CSV file.\n",
    "\n",
    "  Returns:\n",
    "      list: A list of LangChain Document objects.\n",
    "  \"\"\"\n",
    "\n",
    "  documents = []\n",
    "  try:\n",
    "    with open(csv_file_path, 'r', newline='') as csvfile:\n",
    "      reader = csv.DictReader(csvfile)\n",
    "\n",
    "      for row in reader:\n",
    "        # Construct page content (adjust column names and processing as needed)\n",
    "        content = row[\"text\"]\n",
    "\n",
    "                # Create metadata using all other columns\n",
    "        metadata = {key: value for key, value in row.items() if key != \"text\"}\n",
    "\n",
    "        documents.append(Document(page_content=content, metadata=metadata))\n",
    "\n",
    "  except FileNotFoundError:\n",
    "    print(f\"Error: CSV file '{csv_file_path}' not found.\")\n",
    "  except Exception as e:\n",
    "    print(f\"An error occurred while processing the CSV file: {str(e)}\")\n",
    "\n",
    "  return documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "\n",
    "\n",
    "documents = read_csv_to_langchain_documents(\"test.csv\")\n",
    "\n",
    "\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"thenlper/gte-small\")\n",
    "\n",
    "db = Chroma.from_documents(documents, embedding_function)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query = \"yo\"\n",
    "docs = db.similarity_search(query)\n",
    "print(\"docs\")\n",
    "filter_metadata = {\"sentiment\": \"negative\"}\n",
    "filtered_documents = db.filter(where=filter_metadata)\n",
    "\n",
    "print(\"Page Content:\")\n",
    "print(filtered_documents[0].page_content)\n",
    "print(\"Meta Data:\")\n",
    "print(filtered_documents[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain.chains.query_constructor.ir import (\n",
    "    Comparator,\n",
    "    Comparison,\n",
    "    Operation,\n",
    "    Operator,\n",
    "    StructuredQuery,\n",
    ")\n",
    "from langchain.retrievers.self_query.chroma import ChromaTranslator\n",
    "from langchain.retrievers.self_query.elasticsearch import ElasticsearchTranslator\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Search(BaseModel):\n",
    "    query: str\n",
    "    sentiment:str\n",
    "    country: str\n",
    "\n",
    "search_query = Search(query=\"RAG\", sentiment=\"positive\", country=\"Afghanistan\")\n",
    "\n",
    "\n",
    "def construct_comparisons(query: Search):\n",
    "    comparisons = []\n",
    "    if query.sentiment is not None:\n",
    "        comparisons.append(\n",
    "            Comparison(\n",
    "                comparator=Comparator.GT,\n",
    "                attribute=\"sentiment\",\n",
    "                value=query.sentiment,\n",
    "            )\n",
    "        )\n",
    "    if query.country is not None:\n",
    "        comparisons.append(\n",
    "            Comparison(\n",
    "                comparator=Comparator.EQ,\n",
    "                attribute=\"country\",\n",
    "                value=query.country,\n",
    "            )\n",
    "        )\n",
    "    return comparisons\n",
    "\n",
    "\n",
    "comparisons = construct_comparisons(search_query)\n",
    "_filter = Operation(operator=Operator.AND, arguments=comparisons)\n",
    "\n",
    "ChromaTranslator().visit_operation(_filter)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaskedLMOutput(loss=None, logits=tensor([[[ -6.9817,  -6.9306,  -6.9328,  ...,  -6.1200,  -6.0824,  -3.8752],\n",
      "         [ -7.7905,  -7.7737,  -7.9002,  ...,  -7.6229,  -6.5687,  -6.4738],\n",
      "         [ -8.9998,  -8.8548,  -8.6583,  ...,  -7.8098,  -7.9886,  -7.1754],\n",
      "         ...,\n",
      "         [ -9.3453,  -9.5712,  -9.4370,  ...,  -8.5953,  -8.5967,  -8.0357],\n",
      "         [-11.3913, -11.1845, -11.2746,  ...,  -9.1288,  -9.9455,  -4.7532],\n",
      "         [-12.0010, -12.3291, -12.2169,  ..., -10.4999, -10.4241,  -7.1634]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(encoded_input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_dir = \"/microsoftLLM\"\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "saved_model_dir = \"./LLM\"\n",
    "model = AutoModelForCausalLM.from_pretrained(saved_model_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(saved_model_dir)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
