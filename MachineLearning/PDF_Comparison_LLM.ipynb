{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQW_gGY7n-uN"
      },
      "outputs": [],
      "source": [
        "!pip install langchain_community\n",
        "!pip install unstructured\n",
        "!pip install pillow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfminer.six\n",
        "!pip install pillow_heif\n",
        "!pip install unstructured_inference\n",
        "!pip install unstructured_pytesseract\n",
        "!pip install pytesseract\n",
        "!pip install tesseract\n",
        "!sudo apt-get install tesseract-ocr\n"
      ],
      "metadata": {
        "id": "D2TdcYfNY-8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "id": "mGi8S3fravfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVL1Afz5n9qf"
      },
      "outputs": [],
      "source": [
        "!pip install pdf2image\n",
        "!sudo apt-get install poppler-utils"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **For Docx**\n"
      ],
      "metadata": {
        "id": "dDOz3j017Exu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCGAR2Jk7EFE",
        "outputId": "4406a8e7-c302-4158-f272-76725fda41e2"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.2)\n",
            "Installing collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document\n",
        "\n",
        "def read_docx(file_path):\n",
        "    doc = Document(file_path)\n",
        "    full_text = []\n",
        "    for para in doc.paragraphs:\n",
        "        full_text.append(para.text)\n",
        "    return '\\n'.join(full_text)\n",
        "\n",
        "file_path1=\"306 - Technical Services Agreement Linde.docx\"\n",
        "text1 = read_docx(file_path1)\n",
        "\n",
        "file_path2=\"505C-EPC Agreement _20220930 Highlighted.docx\"\n",
        "text2 = read_docx(file_path2)\n",
        "\n"
      ],
      "metadata": {
        "id": "0ECugCjD7UT6"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "JVa1r7I_oBU2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ec30308-a09d-45a0-a2ca-746676856126"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF pages have been converted and saved in 'output_images1'\n"
          ]
        }
      ],
      "source": [
        "from pdf2image import convert_from_path\n",
        "import os\n",
        "\n",
        "# Define the path to the PDF file and the output directory\n",
        "pdf_path = 'book1.pdf'\n",
        "output_dir = 'output_images1'\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Convert PDF pages to images\n",
        "images = convert_from_path(pdf_path)\n",
        "\n",
        "# Save each image in the output directory\n",
        "for i, image in enumerate(images):\n",
        "    image_path = os.path.join(output_dir, f'page_{i + 1}.png')\n",
        "    image.save(image_path, 'PNG')\n",
        "\n",
        "print(f\"PDF pages have been converted and saved in '{output_dir}'\")\n",
        "\n",
        "image_paths1 = [os.path.join(output_dir, f'page_{i + 1}.png') for i in range(len(images))]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pdf2image import convert_from_path\n",
        "import os\n",
        "\n",
        "# Define the path to the PDF file and the output directory\n",
        "pdf_path = 'book2.pdf'\n",
        "output_dir = 'output_images2'\n",
        "\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Convert PDF pages to images\n",
        "images = convert_from_path(pdf_path)\n",
        "\n",
        "# Save each image in the output directory\n",
        "for i, image in enumerate(images):\n",
        "    image_path = os.path.join(output_dir, f'page_{i + 1}.png')\n",
        "    image.save(image_path, 'PNG')\n",
        "\n",
        "print(f\"PDF pages have been converted and saved in '{output_dir}'\")\n",
        "\n",
        "\n",
        "image_paths2 = [os.path.join(output_dir, f'page_{i + 1}.png') for i in range(len(images))]"
      ],
      "metadata": {
        "id": "3joQvXvhC9Tm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49136063-8348-4bfa-cc2d-68a6d8475a70"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF pages have been converted and saved in 'output_images2'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_paths1.remove(\"output_images1/page_2.png\")\n",
        "image_paths2.remove(\"output_images2/page_3.png\")\n",
        "image_paths2.remove(\"output_images2/page_4.png\")"
      ],
      "metadata": {
        "id": "BVaOXxnlbpyZ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_paths1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRShxjSmersL",
        "outputId": "78092eaf-60e5-476c-af2d-5a993e8d3004"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['output_images1/page_1.png', 'output_images1/page_2.png']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "1wf12sa5bcWl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "bc3fc8fbcc9443048b20b9320f85edef",
            "481b7051cf2f4fa6bdfeadbfb8e6b9f8",
            "cf6ddf5f2d5d412a8f9bdeb13063a667",
            "08994b572a974bc189ef9a23eb14c2c7",
            "0209f96515054bf3947f3c3dbc79ed3c",
            "5b6d6d190a0343bb92cba8b4d79239f0",
            "b2c64cb3e0e64074b1dd80c561ad8f2d",
            "70503a86514542af86b7a3bad6fa61d8",
            "b71326d35cda4899977af54a0fa360a9",
            "3a75ea9467ef4dcda454d1c67a0e9f44",
            "686531d80fd4409bb87d4ecf629c3f18"
          ]
        },
        "outputId": "05f02d16-1679-4e46-c7d9-6f2a041f198d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "yolox_l0.05.onnx:   0%|          | 0.00/217M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc3fc8fbcc9443048b20b9320f85edef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import UnstructuredImageLoader\n",
        "from pathlib import Path\n",
        "\n",
        "# Set the folder path where the images are located\n",
        "folder_path = \"output_images1\"\n",
        "\n",
        "# Create a list to store the text from all the images\n",
        "\n",
        "text1=\" \"\n",
        "\n",
        "# Loop through all the files in the folder\n",
        "for image in image_paths1:\n",
        "    # Check if the file is an image\n",
        "    loader = UnstructuredImageLoader(image)\n",
        "\n",
        "    # Load the image and extract the text\n",
        "    doc1 = loader.load()\n",
        "\n",
        "\n",
        "    text1 = text1+doc1[0].page_content\n",
        "\n",
        "    # Add the text to the list\n",
        "\n",
        "#DOC2\n",
        "\n",
        "folder_path = \"output_images2\"\n",
        "\n",
        "# Create a list to store the text from all the images\n",
        "\n",
        "text2=\" \"\n",
        "\n",
        "# Loop through all the files in the folder\n",
        "for image in image_paths2:\n",
        "    # Check if the file is an image\n",
        "    loader = UnstructuredImageLoader(image)\n",
        "\n",
        "    # Load the image and extract the text\n",
        "    doc2 = loader.load()\n",
        "\n",
        "\n",
        "    text2 = text2+doc2[0].page_content\n",
        "\n",
        "    # Add the text to the list\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kR2MezL715h_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ba0ead5-88a8-4196-d987-444dbecf7739"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-chroma\n",
            "  Downloading langchain_chroma-0.1.2-py3-none-any.whl (9.3 kB)\n",
            "Collecting chromadb<0.6.0,>=0.4.0 (from langchain-chroma)\n",
            "  Downloading chromadb-0.5.3-py3-none-any.whl (559 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m559.5/559.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi<1,>=0.95.2 (from langchain-chroma)\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-core<0.3,>=0.1.40 in /usr/local/lib/python3.10/dist-packages (from langchain-chroma) (0.2.11)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-chroma) (1.25.2)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.2.1)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.31.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.8.0)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting posthog>=2.4.0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.18.1)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_api-1.25.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.25.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.46b0-py3-none-any.whl (11 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_sdk-1.25.0-py3-none-any.whl (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.19.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (4.66.4)\n",
            "Collecting overrides>=7.3.1 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (6.4.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.64.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.12.3)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (8.4.2)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (6.0.1)\n",
            "Collecting mmh3>=4.0.1 (from chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.10.6)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.27.0)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi<1,>=0.95.2->langchain-chroma)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi<1,>=0.95.2->langchain-chroma)\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.2 in /usr/local/lib/python3.10/dist-packages (from fastapi<1,>=0.95.2->langchain-chroma) (3.1.4)\n",
            "Requirement already satisfied: python-multipart>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from fastapi<1,>=0.95.2->langchain-chroma) (0.0.9)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi<1,>=0.95.2->langchain-chroma)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi<1,>=0.95.2->langchain-chroma)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.40->langchain-chroma) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.40->langchain-chroma) (0.1.83)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.40->langchain-chroma) (24.1)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.1.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.0.1)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi<1,>=0.95.2->langchain-chroma)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi<1,>=0.95.2->langchain-chroma) (3.7)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.2->fastapi<1,>=0.95.2->langchain-chroma) (2.1.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.40->langchain-chroma) (3.0.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.0.7)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.12.1)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting importlib-metadata<=7.1,>=6.0 (from opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading importlib_metadata-7.1.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.63.2)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.25.0-py3-none-any.whl (17 kB)\n",
            "Collecting opentelemetry-proto==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_proto-1.25.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-instrumentation-asgi==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.46b0-py3-none-any.whl (14 kB)\n",
            "Collecting opentelemetry-instrumentation==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_instrumentation-0.46b0-py3-none-any.whl (29 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_semantic_conventions-0.46b0-py3-none-any.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-util-http==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_util_http-0.46b0-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (67.7.2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.14.1)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.3.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (13.7.1)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.2.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=7.1,>=6.0->opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.19.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.16.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.6.0)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=aba0b63717da543a7fb638ef1af4452ec12875c32a09594e1e7c3e39a46fbf15\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, mmh3, websockets, uvloop, uvicorn, ujson, python-dotenv, overrides, opentelemetry-util-http, opentelemetry-proto, importlib-metadata, httptools, dnspython, deprecated, chroma-hnswlib, bcrypt, asgiref, watchfiles, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, email_validator, opentelemetry-semantic-conventions, opentelemetry-instrumentation, kubernetes, opentelemetry-sdk, opentelemetry-instrumentation-asgi, fastapi-cli, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, fastapi, chromadb, langchain-chroma\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.0.0\n",
            "    Uninstalling importlib_metadata-8.0.0:\n",
            "      Successfully uninstalled importlib_metadata-8.0.0\n",
            "Successfully installed asgiref-3.8.1 bcrypt-4.1.3 chroma-hnswlib-0.7.3 chromadb-0.5.3 deprecated-1.2.14 dnspython-2.6.1 email_validator-2.2.0 fastapi-0.111.0 fastapi-cli-0.0.4 httptools-0.6.1 importlib-metadata-7.1.0 kubernetes-30.1.0 langchain-chroma-0.1.2 mmh3-4.1.0 monotonic-1.6 opentelemetry-api-1.25.0 opentelemetry-exporter-otlp-proto-common-1.25.0 opentelemetry-exporter-otlp-proto-grpc-1.25.0 opentelemetry-instrumentation-0.46b0 opentelemetry-instrumentation-asgi-0.46b0 opentelemetry-instrumentation-fastapi-0.46b0 opentelemetry-proto-1.25.0 opentelemetry-sdk-1.25.0 opentelemetry-semantic-conventions-0.46b0 opentelemetry-util-http-0.46b0 overrides-7.7.0 posthog-3.5.0 pypika-0.48.9 python-dotenv-1.0.1 starlette-0.37.2 ujson-5.10.0 uvicorn-0.30.1 uvloop-0.19.0 watchfiles-0.22.0 websockets-12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Xx8P5Ot11SXU"
      },
      "outputs": [],
      "source": [
        "#Text Splitter and Embeddings\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_community.embeddings.sentence_transformer import (\n",
        "    SentenceTransformerEmbeddings,\n",
        ")\n",
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "import re\n",
        "import langchain\n",
        "\n",
        "def text_splitter_And_Similarity_Search(documents):\n",
        "\n",
        "\n",
        "\n",
        "    model_name=\"BAAI/bge-large-en-v1.5\"\n",
        "    model_kwargs = {\"device\": \"cuda\",\"trust_remote_code\":True}\n",
        "    encode_kwargs = {\"normalize_embeddings\": True}\n",
        "\n",
        "\n",
        "\n",
        "    # text_splitter = RecursiveCharacterTextSplitter(chunk_size=250,chunk_overlap=50)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    embedding_function = SentenceTransformerEmbeddings(\n",
        "    model_name=model_name,\n",
        "    model_kwargs=model_kwargs,\n",
        "    encode_kwargs=encode_kwargs,\n",
        "    )\n",
        "\n",
        "    db = Chroma.from_documents(documents, embedding_function,persist_directory=\"./book22_embed\" )\n",
        "\n",
        "\n",
        "    # embedding_function = SentenceTransformerEmbeddings(model_name=\"thenlper/gte-base\")\n",
        "    # db = Chroma.from_documents(documents, embedding_function )\n",
        "\n",
        "    return db,\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNRSvbRj1VeH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "349bb5c5-c09b-4e0d-ae46-8bb5f3e0e521"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUTpnVU61X-g"
      },
      "outputs": [],
      "source": [
        "!pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TfpXS7S71ZZ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3effe155-fcf7-492a-d5c0-eefa1baaec96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model_name=\"BAAI/bge-large-en-v1.5\"\n",
        "model_kwargs = {\"device\": \"cpu\",\"trust_remote_code\":True}\n",
        "encode_kwargs = {\"normalize_embeddings\": True}\n",
        "\n",
        "\n",
        "\n",
        "    # text_splitter = RecursiveCharacterTextSplitter(chunk_size=250,\n",
        "    #                                                    chunk_overlap=50)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "embedding_function = SentenceTransformerEmbeddings(\n",
        "model_name=model_name,\n",
        "model_kwargs=model_kwargs,\n",
        "encode_kwargs=encode_kwargs,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0s69KQ057Trj",
        "outputId": "c42e561e-8424-45c6-8090-7f7fd821f10d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_chroma.vectorstores.Chroma at 0x78680827b3a0>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hrefqr1y7TZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "A8wnkavx1anI"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.docstore.document import Document\n",
        "\n",
        "def getDocs(text):\n",
        "  docs=Document(page_content=text,metadata={\"source\":\"book\"})\n",
        "  doc=[]\n",
        "  doc.append(docs)\n",
        "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000,\n",
        "                                                       chunk_overlap=0)\n",
        "  documents = text_splitter.split_documents(doc)\n",
        "  return documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "IQRuB9RH1cJ7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "6e226640-61d8-41b0-c0dc-a0c31a57c309"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Document() got an unexpected keyword argument 'page_content'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-a114c171bca5>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# db1=text_splitter_And_Similarity_Search(getDocs(text1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdb2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_splitter_And_Similarity_Search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetDocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-6cb74acbe615>\u001b[0m in \u001b[0;36mgetDocs\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetDocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mdocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"source\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"book\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mdoc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Document() got an unexpected keyword argument 'page_content'"
          ]
        }
      ],
      "source": [
        "# db1=text_splitter_And_Similarity_Search(getDocs(text1))\n",
        "db2=text_splitter_And_Similarity_Search(getDocs(text2))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numba\n",
        "\n",
        "from numba import cuda\n",
        "device = cuda.get_current_device()\n",
        "device.reset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfT6iuuARPic",
        "outputId": "93a77457-a857-4e02-ee36-9b5844d98564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (0.58.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba) (0.41.1)\n",
            "Requirement already satisfied: numpy<1.27,>=1.22 in /usr/local/lib/python3.10/dist-packages (from numba) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "3ggEz5Ci1d4C"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "def check_token_limit(new_documents):\n",
        "  tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n",
        "  tokens=tokenizer(new_documents)\n",
        "  n_tokens=len(tokens.input_ids)\n",
        "  return n_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "dhtkm3s_1fQf"
      },
      "outputs": [],
      "source": [
        "vectordb1 = Chroma(persist_directory=\"./book1111_embed\",embedding_function=embedding_function)\n",
        "vectordb2 = Chroma(persist_directory=\"./book2222_embed\",embedding_function=embedding_function)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uo0eikt2FPgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from accelerate import Accelerator\n",
        "\n",
        "# Initialize Accelerator\n",
        "accelerator = Accelerator()\n",
        "torch.random.manual_seed(0)\n",
        "\n",
        "def start_model():\n",
        "  model_id = \"microsoft/Phi-3-mini-4k-instruct\"\n",
        "\n",
        "  model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=\"auto\",\n",
        "    device_map=\"cuda\",\n",
        "\n",
        "    trust_remote_code=True,\n",
        "  )\n",
        "  assert torch.cuda.is_available(), \"This model needs a GPU to run ...\"\n",
        "\n",
        "  device = torch.cuda.current_device()\n",
        "\n",
        "  model = model.to(device)\n",
        "\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "\n",
        "\n",
        "  pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "  )\n",
        "  return model,tokenizer ,pipe\n",
        "\n",
        "model,tokenizer,pipe=start_model()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408,
          "referenced_widgets": [
            "27bacb1fbfc84a5baa614a582fc8966e",
            "8ebe12d028b6457ba6ab05baaa28ad96",
            "948fd5d92c7049c08b14b9d036cc8264",
            "4c00c23f7199488cb2b64126f8824583",
            "0617a003d46e4d1cb6320954e867b353",
            "7b005b82f1ce460aaddabcdb49292fbc",
            "3cf3e4357a174387a698919404d17a1e",
            "b7dc93ab29c14277bd84fae447a04ab3",
            "d183c4ba11254c1582afada5ddc8562e",
            "faeecacd86a143e5b4094cc825c4045f",
            "71c9fedd9bc44514b36f80a855acf128"
          ]
        },
        "id": "owBnbiQUFH0T",
        "outputId": "9892ef14-9fea-48ac-d81a-c3905c5603bf"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.c1358f8a35e6d2af81890deffbbfa575b978c62f.modeling_phi3:`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
            "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.c1358f8a35e6d2af81890deffbbfa575b978c62f.modeling_phi3:Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "27bacb1fbfc84a5baa614a582fc8966e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-32f350197a6e>\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-36-32f350197a6e>\u001b[0m in \u001b[0;36mstart_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mmodel_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"microsoft/Phi-3-mini-4k-instruct\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m                 \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    559\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3752\u001b[0m                 \u001b[0moffload_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3753\u001b[0m                 \u001b[0merror_msgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3754\u001b[0;31m             \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_pretrained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3755\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3756\u001b[0m                 \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, gguf_path)\u001b[0m\n\u001b[1;32m   4212\u001b[0m                                 )\n\u001b[1;32m   4213\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4214\u001b[0;31m                         new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(\n\u001b[0m\u001b[1;32m   4215\u001b[0m                             \u001b[0mmodel_to_load\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4216\u001b[0m                             \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, loaded_state_dict_keys, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, hf_quantizer, is_safetensors, keep_in_fp32_modules, unexpected_keys)\u001b[0m\n\u001b[1;32m    885\u001b[0m         ):\n\u001b[1;32m    886\u001b[0m             \u001b[0;31m# For backward compatibility with older versions of `accelerate` and for non-quantized params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 887\u001b[0;31m             \u001b[0mset_module_tensor_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mset_module_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m             \u001b[0mhf_quantizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_quantized_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/modeling.py\u001b[0m in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    402\u001b[0m                     \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mold_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m             \u001b[0mnew_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0mnew_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc1_chunks=getDocs(text1)"
      ],
      "metadata": {
        "id": "t1AmlQxjF6pL"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc1_chunks[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVQjtZpAGrtY",
        "outputId": "28e369c4-9076-4e45-db35-ce3b763ce788"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'book'}, page_content='(d) ANNEXURE 7 — INSURANCE REQUIREMENTS;\\n\\n(e) ANNEXURE 13 —- ICV IMPROVEMENT PLAN;\\n\\n(f) ANNEXURE 12 —- HSE REQUIREMENTS;\\n\\n(g) ANNEXURE 3 — SCOPE OF WORK;\\n\\n(h) ANNEXURE 5 — PRICING SCHEDULE;\\n\\n@ ANNEXURE 4 — COMPLETION SCHEDULE;\\n\\n0) ANNEXURE 10 — PROJECT EXECUTION REQUIREMENTS;\\n\\n(k) ANNEXURE 11 —- COMPLETION AND ACCEPTANCE REQUIREMENTS;\\n\\ndd) ANNEXURE 9 —- CONTRACTOR’s SUBMISSIONS;\\n\\n(m) ANNEXURE 6 —- COMPANY PROVIDED FACILITIES; and\\n\\n(n) ANNEXURE 8 — SECURITIES AND FORMS.\\n\\nADNOC-CICV-505A(v6)\\n\\n2\\n\\ninsert the reference numberADNOC Classification: Need-To-Know\\n\\nWith respect to any ANNEXURE(S) listed in Clause 1.3 which are not otherwise listed in this Clause 1.6, lict or ambiguity, then such ANNEXURE(S) shall take the order of in Clause 1.3. in the event that there is a con precedence in which they appear\\n\\nThe PARTIES have agreed that the key provisions set out below shall apply to the AGREEMENT.')"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "generation_args = {\n",
        " \"max_new_tokens\": 300,\n",
        " \"return_full_text\": False,\n",
        "#  \"repetition_penalty\": 1.3,\n",
        " \"temperature\": 0.0,\n",
        " \"do_sample\": False,\n",
        "  # \"top_p\":0.9,\n",
        "}"
      ],
      "metadata": {
        "id": "EbInmakSL-vn"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_questions(retrieved_documents):\n",
        "    document_text = retrieved_documents\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You have been given a chunk of a document. Your job is to generate a complete question that encapsulates all the important insights from that text. The question should be comprehensive and specific, ensuring it can be easily asked to different documents or chunks with similar details. Only provide the question. Do not include any additional information.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Document: {document_text}\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    output = pipe(messages, **generation_args)\n",
        "    print(output)\n",
        "    print(\"working fine generate_question\")\n",
        "\n",
        "    return output[0][\"generated_text\"]\n"
      ],
      "metadata": {
        "id": "bF79qjm6GqC-"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieved_documents(document):\n",
        "\n",
        "  questions=generate_questions(document)\n",
        "\n",
        "  doc1_text = vectordb1.similarity_search_with_score(query=questions,k=4)\n",
        "  doc2_text = vectordb2.similarity_search_with_score(query=questions,k=4)\n",
        "  print(\"working fine_retrieved_documents\")\n",
        "  return doc1_text,doc2_text,questions\n"
      ],
      "metadata": {
        "id": "WhOj03n5MHQ3"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answers(document):\n",
        " doc1_text,doc2_text,question=retrieved_documents(document)\n",
        " print(\"doc1\")\n",
        " print(doc1_text)\n",
        " print(\"doc2\")\n",
        " print(doc2_text)\n",
        " answer1 = [{\n",
        "        \"role\": \"user\",\n",
        "        \"content\" : f\"\"\"\n",
        "You have been a document and a question , Your Job is to Answer the question from the given document precisely and acurately.\n",
        "Only provide the Answer , donot give any further information\n",
        "Here is  the document:\n",
        "{doc1_text}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        " }]\n",
        " answer2 = [{\n",
        "        \"role\": \"user\",\n",
        "        \"content\" : f\"\"\"\n",
        "You have been a document and a question , Your Job is to Answer the question from the given document precisely and acurately.\n",
        "Only provide the Answer , donot give any further information\n",
        "\n",
        "Here is  the document:\n",
        "{doc2_text}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        " }]\n",
        " output1 = pipe(answer1, **generation_args)\n",
        " output2 = pipe(answer2, **generation_args)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " print(\"working fine generate prompt\")\n",
        " return output1[0][\"generated_text\"],output2[0][\"generated_text\"],question\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bjWN7xb6HV4g"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt(document):\n",
        "    answer1, answer2, question = generate_answers(document)\n",
        "\n",
        "    prompt = [{\n",
        "        \"role\": \"user\",\n",
        "        \"content\": (\n",
        "            \"You are tasked with comparing answers from two different documents to the same question:\\n\\n\"\n",
        "            \"Question:\\n\"\n",
        "            f\"{question}\\n\\n\"\n",
        "            \"Your goal is to identify and highlight differences accurately, including numerical details, clauses, and articles. \"\n",
        "            \"Pay attention to instances where the same information is presented in different ways across both documents, such as a fixed number versus a range of numbers. \"\n",
        "            \"Only answer based on the given information; do not provide any additional details.\\n\\n\"\n",
        "            \"Note: Both documents belong to the same company. This context should not be considered a difference.\\n\\n\"\n",
        "            \"Document 1 (Main Document):\\n\"\n",
        "            f\"{answer1}\\n\\n\"\n",
        "            \"Document 2:\\n\"\n",
        "            f\"{answer2}\\n\\n\"\n",
        "            \"Instructions:\\n\"\n",
        "            \"- If a topic or information appears in both documents but is expressed differently (e.g., paraphrased or rephrased), note it as 'Equivalent information presented differently.' \"\n",
        "            \"Specify the clauses or articles where these topics are mentioned.\\n\"\n",
        "            \"- If a numerical detail in Document 1 is compared to a range in Document 2, or vice versa, highlight this difference specifically.\\n\"\n",
        "            \"- If a topic is present in Document 1 but missing in Document 2, state: '[Topic] is missing from Document 2.' \"\n",
        "            \"Specify the clause or article where this topic is mentioned in Document 1.\\n\"\n",
        "            \"- If a topic is present in Document 2 but missing in Document 1, state: '[Topic] is missing from Document 1.' \"\n",
        "            \"Specify the clause or article where this topic is mentioned in Document 2.\\n\"\n",
        "            \"- Ensure you are thorough and accurate in your comparison, confirming the presence or absence of information with careful attention to detail. \"\n",
        "            \"If both documents contain the same information, ensure it is not flagged as missing.\\n\"\n",
        "            \"- Provide a concise comparison for each differing or equivalently presented topic, including the specific clauses or articles where they are discussed.\\n\\n\"\n",
        "            \"Differences and Equivalences:\"\n",
        "        )\n",
        "    }]\n",
        "\n",
        "    return prompt\n"
      ],
      "metadata": {
        "id": "55bttVc5TFwV"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_final_answer(document):\n",
        "\n",
        "  messages=generate_prompt(document)\n",
        "  output = pipe(messages, **generation_args)\n",
        "  print(\"working fine generate answer\")\n",
        "  return output[0][\"generated_text\"],messages\n",
        "\n"
      ],
      "metadata": {
        "id": "GFWo26mKPJiC"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "differences=[]\n",
        "for chunk in doc1_chunks:\n",
        "  current_document=chunk.page_content\n",
        "  result,messages=generate_final_answer(current_document)\n",
        "  print(result)\n",
        "  differences.append(result)"
      ],
      "metadata": {
        "id": "frtzytOhP016"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# current_document=chunk.page_content\n",
        "current_document=\"\"\"PAYMENT OF INDEMNITY\n",
        "Any indemnity provided under Articles 4.3(e), 20.6, 22.3, 41.12, 41.16(d) or this Article 42\n",
        "shall be due by the INDEMNIFYING PARTY to the INDEMNIFIED PARTY within ninety\n",
        "(90) DAYS following either:\n",
        "(i)the notification by the INDEMNIFIED PARTY to the INDEMNIFYING PARTY of\n",
        "the final adjudication by a court or an arbitral tribunal of competent jurisdiction of the\n",
        "claims referred to in Articles 4.3(e), 20.6, 22.3, 41.12, 41.16(d) or Articles 42.1 to 42.5;\n",
        "or\n",
        "(ii)the conclusion of a settlement of claims by the INDEMNIFIED PARTY and the\n",
        "claimant(s), provided that the INDEMNIFYING PARTY approves the terms of such\n",
        "settlement, which approval shall not unreasonably be withheld or delayed.\n",
        "All losses, liabilities, damages and costs which are recoverable under Articles 4.3(e), 20.6, 22.3,\n",
        "41.12, 41.16(d) or this Article 42, other than amounts ordered by a tribunal or agreed in a\n",
        "settlement, shall become due by the INDEMNIFYING PARTY to the INDEMNIFIED PARTY\n",
        "within ninety (90) DAYS following the notification by the INDEMNIFIED PARTY to the\n",
        "INDEMNIFYING PARTY of the final adjudication by a court or an arbitral tribunal of\n",
        "competent jurisdiction of the related claims, or, upon the conclusion of a settlement of the\n",
        "related claims by the INDEMNIFIED PARTY and the claimant(s) in accordance with\n",
        "Article 42.8(a)(ii), as the case may be, provided that the INDEMNIFIED PARTY furnishes\n",
        "proof of the losses, liabilities, damages and/or costs incurred.\"\"\"\n",
        "result,messages=generate_final_answer(current_document)\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "ZiqA2yf-S3zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages"
      ],
      "metadata": {
        "id": "kXncvm7bkKzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "WNF6-oLxpxiP",
        "outputId": "c9402821-8d4e-41ef-99ac-c6fa2648ef96"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Document 1: Finance Project Report\\nTitle: Investment Strategies and Portfolio Management\\n\\nExecutive Summary\\nThis report evaluates the investment strategies and portfolio management approaches adopted by ABC Finance Ltd. The focus is on risk management, asset allocation, and performance measurement over the financial year 2023-2024.\\n\\n1. Introduction\\n1.1 Background\\n\\nABC Finance Ltd. has been a prominent player in the investment sector for over two decades. The firm manages a diverse portfolio consisting of equities, bonds, commodities, and real estate. Established in 2000, ABC Finance Ltd. has consistently demonstrated robust financial performance and strategic growth.\\n\\n1.2 Objectives\\n\\nThe objectives of this report are as follows:\\n1.2.1 To analyze the performance of the investment strategies implemented in the fiscal year 2023-2024.\\n1.2.2 To assess the effectiveness of the risk management techniques.\\n1.2.3 To provide recommendations for future investment strategies.\\n\\n2. Investment Strategies\\n2.1 Asset Allocation\\n\\n2.1.1 Overview\\nAsset allocation is the process of distributing investments among various asset categories such as equities, bonds, commodities, and real estate. The primary goal is to optimize the risk-return profile of the portfolio.\\n\\n2.1.2 Strategy Implemented\\nIn the fiscal year 2023-2024, ABC Finance Ltd. employed a diversified asset allocation strategy:\\n\\nEquities: 50%\\nBonds: 30%\\nCommodities: 10%\\nReal Estate: 10%\\n2.2 Equity Investments\\n\\n2.2.1 Overview\\nEquities are shares of ownership in a corporation, providing investors with a claim on the company's assets and earnings.\\n\\n2.2.2 Performance\\nThe equity investments yielded an average return of 12% over the year. Key stocks in the portfolio included technology and healthcare sectors, which outperformed the market averages.\\n\\n2.3 Fixed-Income Investments\\n\\n2.3.1 Overview\\nFixed-income investments primarily consist of bonds, which are debt instruments issued by corporations and governments.\\n\\n2.3.2 Performance\\nThe fixed-income portfolio achieved an average return of 5%. The portfolio was heavily weighted towards high-grade corporate bonds and government securities.\\n\\n3. Risk Management\\n3.1 Overview\\n\\nRisk management involves identifying, assessing, and prioritizing risks followed by coordinated efforts to minimize, monitor, and control the probability or impact of unfortunate events.\\n\\n3.2 Techniques Used\\n\\n3.2.1 Diversification\\nABC Finance Ltd. practiced diversification by spreading investments across different asset classes and sectors to reduce exposure to any single asset or risk.\\n\\n3.2.2 Hedging\\nHedging strategies included the use of derivative instruments such as options and futures to mitigate potential losses in the portfolio.\\n\\n3.3 Performance of Risk Management\\n\\nThe risk management strategies were effective, with the portfolio experiencing a maximum drawdown of 8% during the most volatile periods of the market.\\n\\n4. Performance Measurement\\n4.1 Metrics Used\\n\\nPerformance measurement is critical to evaluate the success of investment strategies. The following metrics were used:\\n\\n4.1.1 Return on Investment (ROI)\\nThe overall ROI for the portfolio was 8.5%.\\n\\n4.1.2 Sharpe Ratio\\nThe Sharpe Ratio, which measures the risk-adjusted return, was 1.2.\\n\\n4.1.3 Alpha\\nAlpha, representing the excess return of the portfolio relative to the benchmark, was 2.3%.\\n\\n4.2 Comparative Analysis\\n\\nThe portfolio outperformed the benchmark index by 2%, indicating effective management and strategy implementation.\\n\\n5. Policies\\n5.1 Investment Policy Statement (IPS)\\n\\n5.1.1 Purpose\\nThe IPS outlines the investment philosophy and guidelines for ABC Finance Ltd.\\n\\n5.1.2 Key Components\\n\\nInvestment Objectives: Achieving a balanced growth of capital.\\nRisk Tolerance: Moderate, with an emphasis on capital preservation.\\nTime Horizon: Long-term, exceeding five years.\\n5.2 Compliance Policy\\n\\n5.2.1 Regulatory Compliance\\nABC Finance Ltd. adheres to all relevant regulatory requirements set by financial authorities.\\n\\n5.2.2 Ethical Standards\\nThe firm maintains high ethical standards, ensuring transparency and integrity in all investment activities.\\n\\n6. Conclusion and Recommendations\\n6.1 Conclusion\\n\\nThe investment strategies adopted by ABC Finance Ltd. in the fiscal year 2023-2024 were successful in achieving the desired objectives of risk management and return optimization.\\n\\n6.2 Recommendations\\n\\n6.2.1 Future Strategies\\n\\nEnhance diversification by exploring emerging markets.\\nIncrease allocation to technology and healthcare sectors.\\nImplement more advanced hedging techniques to mitigate risks.\\n6.2.2 Policy Enhancements\\n\\nRegularly review and update the Investment Policy Statement.\\nStrengthen compliance mechanisms to adapt to changing regulatory environments.\\nThis completes the first document. Please let me know when you are ready for the second document.\\n\\n\\n\\n\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bc3fc8fbcc9443048b20b9320f85edef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_481b7051cf2f4fa6bdfeadbfb8e6b9f8",
              "IPY_MODEL_cf6ddf5f2d5d412a8f9bdeb13063a667",
              "IPY_MODEL_08994b572a974bc189ef9a23eb14c2c7"
            ],
            "layout": "IPY_MODEL_0209f96515054bf3947f3c3dbc79ed3c"
          }
        },
        "481b7051cf2f4fa6bdfeadbfb8e6b9f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b6d6d190a0343bb92cba8b4d79239f0",
            "placeholder": "​",
            "style": "IPY_MODEL_b2c64cb3e0e64074b1dd80c561ad8f2d",
            "value": "yolox_l0.05.onnx: 100%"
          }
        },
        "cf6ddf5f2d5d412a8f9bdeb13063a667": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70503a86514542af86b7a3bad6fa61d8",
            "max": 216625723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b71326d35cda4899977af54a0fa360a9",
            "value": 216625723
          }
        },
        "08994b572a974bc189ef9a23eb14c2c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a75ea9467ef4dcda454d1c67a0e9f44",
            "placeholder": "​",
            "style": "IPY_MODEL_686531d80fd4409bb87d4ecf629c3f18",
            "value": " 217M/217M [00:05&lt;00:00, 297MB/s]"
          }
        },
        "0209f96515054bf3947f3c3dbc79ed3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b6d6d190a0343bb92cba8b4d79239f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2c64cb3e0e64074b1dd80c561ad8f2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70503a86514542af86b7a3bad6fa61d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b71326d35cda4899977af54a0fa360a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a75ea9467ef4dcda454d1c67a0e9f44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "686531d80fd4409bb87d4ecf629c3f18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27bacb1fbfc84a5baa614a582fc8966e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ebe12d028b6457ba6ab05baaa28ad96",
              "IPY_MODEL_948fd5d92c7049c08b14b9d036cc8264",
              "IPY_MODEL_4c00c23f7199488cb2b64126f8824583"
            ],
            "layout": "IPY_MODEL_0617a003d46e4d1cb6320954e867b353"
          }
        },
        "8ebe12d028b6457ba6ab05baaa28ad96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b005b82f1ce460aaddabcdb49292fbc",
            "placeholder": "​",
            "style": "IPY_MODEL_3cf3e4357a174387a698919404d17a1e",
            "value": "Loading checkpoint shards:   0%"
          }
        },
        "948fd5d92c7049c08b14b9d036cc8264": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7dc93ab29c14277bd84fae447a04ab3",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d183c4ba11254c1582afada5ddc8562e",
            "value": 0
          }
        },
        "4c00c23f7199488cb2b64126f8824583": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_faeecacd86a143e5b4094cc825c4045f",
            "placeholder": "​",
            "style": "IPY_MODEL_71c9fedd9bc44514b36f80a855acf128",
            "value": " 0/2 [00:02&lt;?, ?it/s]"
          }
        },
        "0617a003d46e4d1cb6320954e867b353": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b005b82f1ce460aaddabcdb49292fbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cf3e4357a174387a698919404d17a1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7dc93ab29c14277bd84fae447a04ab3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d183c4ba11254c1582afada5ddc8562e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "faeecacd86a143e5b4094cc825c4045f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71c9fedd9bc44514b36f80a855acf128": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}